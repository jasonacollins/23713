# 5.2 Intuition versus statistical prediction

The story of Orley Ashenfelter's prediction of wine quality is not an isolated example. 

In 1954, the experimental psychologist Paul Meehl published *Clinical versus Statistical Prediction*. Meehl catalogued twenty empirical competitions between statistical methods and clinical judgement, involving prediction tasks such as academic results, psychiatric prognosis after electroshock therapy, and parole violation. The results were consistently victory for the statistical model or a tie with the clinical decision maker. In only one study could Meehl generously give a point to the experts.

Similarly, William Grove and his colleagues (2000) looked at 136 studies in medicine and psychiatry in which models had been compared to expert judgement. In 63 of these studies, the model was superior. In 65 there was a tie. This left 8 studies, out of 136, in which the expert was the better option.

## Why might some models outperform?

Many of the decision making problems that we discussed in the first module are eliminated by the use of models. 

### Noise

One of the major reasons that models can outperform is the *noise* in human decision making. Model, in contrast to humans, are typically consistent, returning the same decision each time.

An interesting implication of this difference in consistency is that models designed to *predict the decisions of human decision makers* typically outperform the decision makers whose decisions are used to develop the model. When developing a predictive model, you normally develop it using the outcome of interest. For example, if seeking to predict whether a loan applicant will default on a loan, develop a model using long-term borrower outcomes and their characteristics. In a technique called bootstrapping (not to be confused with the statistical term bootstrapping), you don't use the loan outcomes to develop the model, but rather historic predictions by loan assessors of whether a borrower will default. This use of predicted rather than actual default means that there will be errors in the data on which you are building your model. Despite this, bootstrapping can be effective, largely due to the removal of noise. For example, in one study, models developed from decisions of clinical psychologists tended to outperform most of those same psychologists in differentiating psychotic from neurotic patients.

### The outside view

Another reason for the success of models is that they provide an "outside view", which can overcome problems such as overplacement, overestimation, availability, representativeness, and anchoring and adjustment. We will discuss this in the next section.

## References

Goldberg (1970) "Man Versus Model of Man: A rationale, plus some evidence, for a method if improving on clinical inferences", *Psychological Bulletin*, 73(6), 422-432, https://doi.org/10.1037/h0029230

Grove et al (2000) "Clinical Versus Mechanical Prediction: A Meta-Analysis", *Psychological Assessment*, 12(1), 19-30, https://content.apa.org/doi/10.1037/1040-3590.12.1.19

Meehl (1954) *Clinical versus Statistical Prediction*, University of Minnesota
